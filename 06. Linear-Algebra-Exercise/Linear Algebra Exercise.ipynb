{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.transforms import Affine2D\n",
    "import skimage.io\n",
    "# Write your imports here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Algebra Exercise\n",
    "## Vectors, Matrices, Transformations. Applications of Linear Algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1. Basis Vectors in 2D Coordinate Space\n",
    "We know that for an n-dimensional vector space, we need **exactly n** vectors to form a basis. Let's visualize that.\n",
    "\n",
    "The function you wrote last time for visualizing complex numbers can be extended to visualize any set of vectors. If you haven't already written that, have a look at [this StackOverflow post](https://stackoverflow.com/questions/12265234/how-to-plot-2d-math-vectors-with-matplotlib). You need to use the `quiver()` function which accepts the $x$ and $y$ coordinates of the start and end points.\n",
    "\n",
    "Write a function which accepts an array of vectors in the format `[start_x, start_y, end_x, end_y]` and plots them. Optionally, you can add different colors. When you call `quiver()` pass `color = colors` as the last parameter and it will take care of them.\n",
    "\n",
    "Make sure to leave enough space on the axes. `quiver()` doesn't resize the plot area automatically to fit everything. You can do this manually. A simple `plt.xlim(-10, 10)` and `plt.ylim(-10, 10)` will do the job but you can do much better if you wish :)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_vectors(vectors, colors):\n",
    "    \"\"\"\n",
    "    Plots vectors on the xy-plane. The `vectors` parameter is a Python list.\n",
    "    Each vector is specified in the format [start_x, start_y, end_x, end_y]\n",
    "    \"\"\"\n",
    "    # Write your code here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_vectors([[0, 0, 2, 3]], [\"red\"]) # One vector\n",
    "plot_vectors([[0, 0, 1, 0], [0, 0, 0, 1]], [\"red\", \"blue\"]) # Two orthogonal vectors\n",
    "plot_vectors([[1, 1, -2, 3], [2, 1, -2.5, 1.5], [-3.2, -1.5, 0, 4.3]], [\"red\", \"blue\", \"orange\"]) # Three arbitrary vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that any 2 linearly independent vectors can form a basis in 2D space. This means that every other vector can be represented as their linear combination. It will be easiest to see this in the standard basis of 2D space.\n",
    "\n",
    "We start by defining the two basis vectors: $e_1, e_2$. Then, we choose an arbitrary vector $v$. We know that it can be expressed as a linear combination $$ v = \\lambda_1e_1 + \\lambda_2e_2 $$\n",
    "\n",
    "Finding the unknown coefficients is the same as solving a linear system with as many equations as there are basis vectors (2 in this case). We can do this by using `np.linalg.solve()`.\n",
    "\n",
    "**Note:** If you want to write `lambda` in Python for some reason, use the variable name `lamda` since `lambda` is a reserved keyword."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_linear_combination_coefficients(e1, e2, v):\n",
    "    \"\"\"\n",
    "    Returns the coordinates of the representation of v in the basis {e_1, e_2}.\n",
    "    That is, the unknown coefficients in the linear combination v = lambda_1 * e_1 + lambda_2 * e_2\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e1, e2 = [[1, 0], [0, 1]]\n",
    "v = [3.5, 8.6]\n",
    "# Find the unknown coefficients. Extract the logic in a function.\n",
    "# It should accept the two basis vectors and the one we need to represent\n",
    "# and should return the two coefficients\n",
    "coefficients = find_linear_combination_coefficients(e1, e2, v)\n",
    "print(\"Coefficients: \", str(coefficients))\n",
    "# Plot the three vectors\n",
    "plot_vectors([[0, 0, i[0], i[1]] for i in [e1, e2, v]], [\"red\", \"blue\", \"green\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coefficents should be the same as the vector's coordinates. That's because we were extremely careful in choosing a basis.\n",
    "\n",
    "We know, however, that any pair of linearly independent vectors forms a basis in 2D space. So, let's try this.\n",
    "\n",
    "Choose two arbitrary vectors (in the code they are `[2, 3]` and `[-5, 1]` but feel free to change them as you wish). Represent $v$ as their linear combination and print the coefficients. After that, plot the resulting vectors to verify visually that the third one is the linear combination of the other two with the coefficients that you saw."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e1, e2 = [[2, 3], [-5, 1]]\n",
    "coefficients = find_linear_combination_coefficients(e1, e2, v)\n",
    "print(\"Coefficients: \", str(coefficients))\n",
    "plot_vectors([[0, 0, i[0], i[1]] for i in [e1, e2, v]], [\"red\", \"blue\", \"green\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we did was **changing the basis**. We represented **the same original vector $v$** in the new coordinates. We didn't change the geometric object $v$ itself; it still looks the same in the plot. We only changed our viewpoint. This is what change of basis is all about: changing viewpoints.\n",
    "\n",
    "Let's also see what an \"orthogonal\" basis is: the basis vectors are orthogonal to each other. You can find online how to compute orthogonal vectors but we don't need that. A definition of orthogonal vectors is: a set of two vectors $a, b$ such that $a.b = 0$. One such set of vectors is `[3, 4], [-4, 3]`.\n",
    "\n",
    "Represent the same vector $v$ in the orthogonal basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e1, e2 = [[3, 4], [-4, 3]]\n",
    "coefficients = find_linear_combination_coefficients(e1, e2, v)\n",
    "print(\"Coefficients: \", str(coefficients))\n",
    "plot_vectors([[0, 0, i[0], i[1]] for i in [e1, e2, v]], [\"red\", \"blue\", \"green\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's choose a more visually pleasing basis: one whose basis vectors are **collinear** (parallel) to the coordinate axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e1, e2 = [[0, 5], [4, 0]]\n",
    "coefficients = find_linear_combination_coefficients(e1, e2, v)\n",
    "print(\"Coefficients: \", str(coefficients))\n",
    "plot_vectors([[0, 0, i[0], i[1]] for i in [e1, e2, v]], [\"red\", \"blue\", \"green\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you've seen the coordinates of $v$ in different **bases** (plural form of \"basis\"). You can see that algebra doesn't really care what the basis vectors are. We simply need *some* point of reference.\n",
    "\n",
    "You can also see the transition from an arbitrary basis, to an orthogonal basis, to an orthonormal basis, to the standard basis (which is orthonormal **AND** aligned to the xy axes). You can also see that the standard basis gives us the easiest possible representation of a vector. That's why it's so useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2. Vectorization in `numpy`\n",
    "As programmers, we're used to writing for-loops to iterate over collections. This is quite OK but in Python makes the code slow (because it's an interpreted, dynamically-typed language). For example, a \"standard\" way of summing an array would be\n",
    "```python\n",
    "x = [2, 3, 8, -2.3, 0, 15]\n",
    "sum = 0\n",
    "for i in range(len(x)):\n",
    "    sum += x[i]\n",
    "print(sum)\n",
    "```\n",
    "\n",
    "However, there are better ways to do this. `numpy` works in C \"behind the scenes\". This means that:\n",
    "1. Operations in C are very, very, VERY fast\n",
    "2. Communication between C and Python is slow\n",
    "\n",
    "This means we should prepare our code to use `numpy` arrays as much as possible. First of all, this gives us a great computational advantage: the code is very fast. Second, it will look simpler and more beautiful. Compare the previous code with this one:\n",
    "```python\n",
    "x = [2, 3, 8, -2.3, 0, 15]\n",
    "numpy_sum = np.sum(x)\n",
    "print(numpy_sum)\n",
    "```\n",
    "\n",
    "Of course, the for-loop is still done, it's just hidden.\n",
    "\n",
    "The basic rule is **whenever possible, avoid looping and use vectors and matrices**. Sometimes it's impossible to avoid loops and that's OK.\n",
    "\n",
    "Let's create a performance test. Create a large array of random numbers. You can use `np.random.random()`. Sum the array using `numpy` and using the for-loop. Compare the times. In some cases, the performance difference will be several hundred times (e.g. length = $1.10^7$, difference $\\approx 2000$ times: $\\approx 0.01ms$ for the `sum()` and $\\approx 2s$ for the loop).\n",
    "\n",
    "Don't forget to see that the sums are equal. A fast but incorrect algorihm is not an option :).\n",
    "\n",
    "Next, call the function for different lengths and create two plots showing the time it takes to multiply different-length arrays. **Idea:** You can plot them on two separate y-axes on the same plot. Look at the `twiny()` function. See how much time it takes to perform both operations.\n",
    "\n",
    "Plot another plot: speedup versus length. Plot the length on the x-axis and the speedup (`np_sum_time / for_loop time`) on the y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's one slight warning to using vectors. If we don't know what we're doing we might get very hard-to-detect bugs.\n",
    "\n",
    "Let's look at vector multiplication. In algebra we may write:\n",
    "$$ \\begin{bmatrix}\n",
    "2 \\\\\n",
    "3 \\\\\n",
    "4\n",
    "\\end{bmatrix}.\n",
    " \\begin{bmatrix}\n",
    "5 \\\\\n",
    "-2 \\\\\n",
    "3\n",
    "\\end{bmatrix}=16$$\n",
    "\n",
    "This is the same as\n",
    "$$ \\begin{bmatrix}\n",
    "2 & 3 & 4\n",
    "\\end{bmatrix}.\n",
    " \\begin{bmatrix}\n",
    "5 & -2 & 3\n",
    "\\end{bmatrix}=16$$\n",
    "\n",
    "In vector multiplication, rows and columns don't really matter. However, most of the time we want to use **the matrix convention**: \"rows times columns\". This means that both products above are undefined. Also, the inner product is\n",
    "$$ \\begin{bmatrix}\n",
    "2 & 3 & 4\n",
    "\\end{bmatrix}\n",
    ".\n",
    " \\begin{bmatrix}\n",
    "5 \\\\\n",
    "-2 \\\\\n",
    "3\n",
    "\\end{bmatrix}=16$$\n",
    "\n",
    "The inverse operation, following our convention, will return a matrix (this is called **outer product**):\n",
    "\n",
    "$$ \\begin{bmatrix}\n",
    "2 \\\\\n",
    "3 \\\\\n",
    "4\n",
    "\\end{bmatrix}.\n",
    " \\begin{bmatrix}\n",
    "5 & -2 & 3\n",
    "\\end{bmatrix}=\n",
    "\\begin{bmatrix}\n",
    "10 & -4 & 6 \\\\\n",
    "15 & -6 & -9 \\\\\n",
    "20 & -8 & 12\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "Let's compare how the default `numpy` behaviour does and how we can impose our convention.\n",
    "\n",
    "First, let's create the arrays. Next, multiply them. Everything should look fine... until we look at the shapes of `x` and `y` which are `(3,)`. This kind of array is called **rank-1 array**. The matrix convention **DOES NOT** apply to it. One big error is evident when we try to transpose them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([2, 3, 4])\n",
    "y = np.array([5, -2, 3])\n",
    "print(\"x.y =\", str(x.dot(y)))\n",
    "\n",
    "print(\"x.shape:\", x.shape)\n",
    "print(\"y.shape:\", y.shape)\n",
    "print(\"x:\", x)\n",
    "print(\"x transpose:\", x.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transposition **DID NOT** turn our row-vector into a column vector! This is correct but **does not follow the matrix convention**.\n",
    "\n",
    "How do we follow the matrix convention then? Simple, just represent the vectors as matrices (2D arrays)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[2, 3, 4]]) # Row vector\n",
    "y = np.array([[5], [-2], [3]]) # Column vector\n",
    "\n",
    "print(\"x.shape:\", x.shape)\n",
    "print(\"y.shape:\", y.shape)\n",
    "print(\"x.y:\\n\", x.dot(y)) # Dot product -> still looks like a matrix\n",
    "print(\"y.x:\\n\", y.dot(x)) # Outer product -> matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This simple convention can save us a lot of trouble in the future, especially when dealing with more complicated code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3. Visualizing Linear Transformations\n",
    "Write a code which visualizes a linear transformation. It should show \"the old space\" and \"the new space\" imposed on it.\n",
    "\n",
    "Actually, if you don't want to write the code, I've already provided something for you. The following cell contains the `visualize_transform.py` code from last time. We'll examine it and see how we can use it to show our own transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_transformation(matrix, plot_title):\n",
    "    fig = plt.figure()\n",
    "    plt.axis(\"equal\")\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    # Limits, labels and grid\n",
    "    ax.set_xlim(-5, 5)\n",
    "    ax.set_ylim(-5, 5)\n",
    "    ax.set_xticks(np.arange(ax.get_xlim()[0], ax.get_xlim()[1] + 1))\n",
    "    ax.set_yticks(np.arange(ax.get_ylim()[0], ax.get_ylim()[1] + 1))\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.grid()\n",
    "    ax.set_title(plot_title)\n",
    "\n",
    "    # Unit vectors\n",
    "    ax.quiver([0, 0], [0, 0], [1, 0], [0, 1], color = [\"red\", \"blue\"], alpha = 0.2, units = \"xy\", scale = 1)\n",
    "\n",
    "    # Transformation\n",
    "    matrix = [\n",
    "        [matrix[0][0], matrix[0][1], 0],\n",
    "        [matrix[1][0], matrix[1][1], 0],\n",
    "        [0, 0, 1],\n",
    "    ]\n",
    "    t = Affine2D(matrix)\n",
    "\n",
    "    [min_x, max_x, min_y, max_y] = [2 * ax.get_xlim()[0], 2 * ax.get_xlim()[1] + 1, 2 * ax.get_ylim()[0], 2 * ax.get_ylim()[1] + 1]\n",
    "\n",
    "    # New (transformed) grid lines\n",
    "    # Horizontal\n",
    "    for y in np.arange(min_y, max_y):\n",
    "        ax.plot([min_x, max_x], [y] * 2, color = \"red\", linestyle = \"--\", linewidth = 2, transform = t + ax.transData)\n",
    "    # Vertical\n",
    "    for x in np.arange(min_x, max_x):\n",
    "        ax.plot([x] * 2, [min_y, max_y], color = \"blue\", linestyle = \"--\", linewidth = 2, transform = t + ax.transData)\n",
    "\n",
    "    # New (transformed) unit vectors\n",
    "    new_x = t.transform_affine([1, 0])\n",
    "    new_y = t.transform_affine([0, 1])\n",
    "    ax.quiver([0, 0], [0, 0], [new_x[0], new_y[0]], [new_x[1], new_y[1]], color = [\"red\", \"blue\"], units = \"xy\", angles = \"xy\", scale = 1)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code is mostly \"housekeeping\" - making the plot look nicer. It basically consits of several parts:\n",
    "1. Visualize gridlines\n",
    "2. Create the transformation from the matrix: `t = Affine2D(matrix)`\n",
    "3. Visualize transformed gridlines\n",
    "\n",
    "A quirk with `Affine2D()` is that it uses a 3x3 matrix. What's more, the last row is always `[0, 0, 1]`. This is because the third column corresponds to moving (translation) of the entire coordinate system. As you can imagine, this doesn't leave the origin fixed, therefore **translation is not a linear transformation**. It's an affine transformation, which is exactly what the code does. More info [here](https://stackoverflow.com/questions/10698962/why-do-2d-transformations-need-3x3-matrices).\n",
    "For our purposes, we defined the 2D transformation matrix as:\n",
    "$$ T=\\begin{bmatrix}\n",
    "a & b \\\\\n",
    "c & d\n",
    "\\end{bmatrix} $$\n",
    "which we'll pass to the function as\n",
    "$$ T=\\begin{bmatrix}\n",
    "a & b & 0 \\\\\n",
    "c & d & 0 \\\\\n",
    "0 & 0 & 1\n",
    "\\end{bmatrix} $$\n",
    "\n",
    "**Note:** If you want to visualize translations, feel free to do so.\n",
    "\n",
    "Let's see what various transformations look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identity\n",
    "matrix = [\n",
    "    [1, 0],\n",
    "    [0, 1]\n",
    "]\n",
    "\n",
    "visualize_transformation(matrix, r\"$\\mathrm{Identity\\ transformation}$\")\n",
    "\n",
    "# Scaling\n",
    "matrix = [\n",
    "    [2, 0],\n",
    "    [0, 1]\n",
    "]\n",
    "\n",
    "visualize_transformation(matrix, r\"$\\mathrm{Scaling}$\")\n",
    "\n",
    "# Shear\n",
    "matrix = [\n",
    "    [1, 2],\n",
    "    [-1, 1]\n",
    "]\n",
    "\n",
    "visualize_transformation(matrix, r\"$\\mathrm{Shear}$\")\n",
    "\n",
    "# Rotation\n",
    "matrix = [\n",
    "    [np.cos(np.radians(30)), -np.sin(np.radians(30))],\n",
    "    [np.sin(np.radians(30)), np.cos(np.radians(30))]\n",
    "]\n",
    "\n",
    "visualize_transformation(matrix, r\"$\\mathrm{30^{\\circ}\\ rotation}$\")\n",
    "\n",
    "# Projection (linearly dependent rows)\n",
    "matrix = [\n",
    "    [1, 2],\n",
    "    [2, 4]\n",
    "]\n",
    "\n",
    "visualize_transformation(matrix, r\"$\\mathrm{Projection\\ (linearly\\ dependent\\ rows)}$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to experiment with other matrices and to see what transformation they will result in. Also feel free to write better visualization code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4. Images as Matrices. Image arithmetic\n",
    "One direct use of matrices and transformations is images. An image is a 2D array (i.e. matrix) of pixels. If it's grayscale, each pixel will be an integer from 0 to 255:\n",
    "$$ I=\\begin{bmatrix}\n",
    "20 & 45 & 83 & \\dots \\\\\n",
    "38 & 182 & 200 & \\dots \\\\\n",
    "\\dots & \\dots & \\dots & \\dots \\\\\n",
    "\\end{bmatrix} $$\n",
    "\n",
    "In an RGB image, each pixel contains three values, corresponding to $R$, $G$ and $B$.\n",
    "\n",
    "A bigger number means more brightness in the corresponding channel, for example `[255, 0, 0]` is a completely red pixel. `[0, 0, 0]` is a black pixel, and `[255, 255, 255]` is a white pixel.\n",
    "\n",
    "Because we treat images as matrices, we can peform arithmetic operations on them.\n",
    "\n",
    "To show an image, you can use `plt.imshow()`.\n",
    "\n",
    "#### Opening an image from the Internet\n",
    "This one proves not to be easy. However, there's a library for working with images called `scikit-image` which solves most of our problems. Even better, it returns a `numpy` array, which is perfect for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(url):\n",
    "    img = skimage.io.imread(url)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_image_url = \"https://d17fnq9dkz9hgj.cloudfront.net/uploads/2012/11/140272627-grooming-needs-senior-cat-632x475.jpg\"\n",
    "cat_image = read_image(cat_image_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_image[0][0] # First pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cat_image)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In most cases, it's useful to treat the channels one by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_image_r, cat_image_g, cat_image_b = [cat_image[:, :, i] for i in range(3)]\n",
    "f, (ax_r, ax_g, ax_b) = plt.subplots(1, 3, figsize = (10, 5))\n",
    "ax_r.imshow(cat_image_r, cmap = \"gray\")\n",
    "ax_r.set_title(\"Red channel\")\n",
    "ax_g.imshow(cat_image_g, cmap = \"gray\")\n",
    "ax_g.set_title(\"Green channel\")\n",
    "ax_b.imshow(cat_image_b, cmap = \"gray\")\n",
    "ax_b.set_title(\"Blue channel\")\n",
    "plt.setp([ax_r, ax_g, ax_b], xticks = [], yticks = []) # Remove axis ticks\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we simply add the channels together, without making them red, green or blue, we'll get a grayscale image. Note that this doesn't appear very pleasing. This is because the human eye perceives different colors differently.\n",
    "\n",
    "Note that we first need to \"normalize\" each channel, that is, divide by 255. This will rescale all values. Instead of $[0; 255]$, they'll be in the range $[0; 1]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_image_r_normalized, cat_image_g_normalized, cat_image_b_normalized = [\n",
    "    channel / 255 for channel in [cat_image_r, cat_image_g, cat_image_b]\n",
    "] \n",
    "cat_image_gray = (cat_image_r_normalized + cat_image_g_normalized + cat_image_b_normalized) / 3.0  \n",
    "plt.imshow(cat_image_gray, cmap = \"gray\")\n",
    "plt.title(\"Average grayscale image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The eye is more sensitive to greens than reds or blues. There are several ways to apply that correction, but we'll use [this one](https://stackoverflow.com/questions/14330/rgb-to-monochrome-conversion). This is called **luminance correction** (or **gamma correction**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_image_gray_corrected = (0.299 * cat_image_r_normalized + \n",
    "                            0.587 * cat_image_g_normalized + \n",
    "                            0.114 * cat_image_b_normalized)\n",
    "plt.gca().imshow(cat_image_gray_corrected, cmap = plt.cm.gray)\n",
    "plt.title(\"Gamma-corrected grayscale image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to create an artistic grayscale image, we can always change the coefficients. Feel free to experiment with this.\n",
    "\n",
    "So, there we go. We just performed matrix operations on images. Later, we'll talk about matrix multiplication and convolution, which is a very cool way of processing images.\n",
    "\n",
    "For the time being, let's just try one more thing. The **image histogram** will give us information of how bright our image is. On the x-axis, there are pixel values from 0 to 255. On the y-axis, there is the count of all values, for example 10 pixels with value 0, 30 pixels with value 1 and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(cat_image_gray.ravel(), bins = 256, color = \"black\")\n",
    "plt.title(\"Uncorrected image histogram\")\n",
    "plt.show()\n",
    "plt.hist(cat_image_gray_corrected.ravel(), bins = 256, color = \"red\")\n",
    "plt.title(\"Corrected image histogram\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Represent the image as a single-dimensional vector\n",
    "hist_vector = cat_image_gray.ravel()\n",
    "\n",
    "# Normalize the image to have values in the range [0; 1]\n",
    "hist_vector = hist_vector / (hist_vector.max() - hist_vector.min())\n",
    "\n",
    "plt.hist(hist_vector, bins = 256, color = \"black\", alpha = 0.5, label = \"Uncorrected\")\n",
    "plt.hist(cat_image_gray_corrected.ravel(), bins = 256, color = \"red\", alpha = 0.5, label = \"Corrected\")\n",
    "plt.xlim(0, 1)\n",
    "plt.title(\"Image histograms comparison\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your turn.** Using the code above, display each image channel (1 row, 3 columns). Below each channel, show the histogram corresponding to that channel. Use the previous code pieces as a reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * Problem 5. Perspective Correction\n",
    "Let's now look at transformations. A **homography** is a function that maps a pixel from one image onto a pixel from another image.\n",
    "\n",
    "If a camera looks at an image, it can see a tilted, slanted and rotated version of the same image. It's easier to show than to tell:\n",
    "\n",
    "<img src=\"perspective.gif\" />\n",
    "\n",
    "The camera sees a **transformed** version of the original image. Note, however, those things:\n",
    "1. There's no translation (or if there is, it's irrelevant)\n",
    "2. All lines in the object are lines in the image\n",
    "3. Lines remain parallel and equally spaced\n",
    "\n",
    "This means that the camera sees a **linear transformation** of the original object.\n",
    "\n",
    "This transformation maps 2D space to 2D space which means its determinant is not zero. Which, in turn, means that we can **invert** the transformation matrix and see what the original image looks like.\n",
    "\n",
    "We just transferred a problem in image processing to a problem in linear algebra.\n",
    "\n",
    "This kind of processing has many uses. It allows us to align multiple images, it's also very useful in OCR (optical character recognition) software... and basically, it's a way to **standardize different perspectives**.\n",
    "\n",
    "Since we are in 2D space, we need to find 2 basis vectors and then specify how we want to transform them.\n",
    "\n",
    "Follow [this tutorial](http://www.learnopencv.com/homography-examples-using-opencv-python-c/) on OpenCV, a library for computer vision. You'll need to install it first.\n",
    "\n",
    "**Note:** You can use the `read_image()` function to read the image, and `plt.imshow()` instead of `cv.imshow()`. It's simpler to use `OpenCV` just for finding the perspective correction matrix.\n",
    "\n",
    "For more information about linear transformations on images in OpenCV, you can have a look at [this tutorial](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_geometric_transformations/py_geometric_transformations.html#geometric-transformations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * Problem 6. Eigenvalues and Eigenvectors\n",
    "Some transformations are special. Let's examine this visually.\n",
    "\n",
    "Modify the code in the transformation visualization example. Instead of the two basis vectors, it should now accept **a vector as a parameter** and it should show that vector in the old and new coordinates. This should be simple enough to do :)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_transformed_vector(matrix, vec, title):\n",
    "    \"\"\"\n",
    "    Shows the vector (starting at (0; 0)) before and after the transformation\n",
    "    given by the specified matrix\n",
    "    \"\"\"\n",
    "    # Write your code here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now have a look at the matrix given below:\n",
    "$$ T = \\begin{bmatrix}\n",
    "2 & -4 \\\\\n",
    "-1 & -1\n",
    "\\end{bmatrix} $$\n",
    "\n",
    "See how the transformation acts on a arbitrary vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = np.array([[2, -4, 0], [-1, -1, 0], [0, 0, 1]])\n",
    "visualize_transformed_vector(matrix, [2, 3], \"Transformation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, it... transforms it somehow. Let's try another vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_transformed_vector(matrix, [-4, 1], \"Transformation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hm... the vector should be **scaled only**. That is, the entire matrix multiplication acts like a scalar multiplication for this special vector. Because it's so special, it's given a name - it's an **eigenvector** of that matrix. The factor which scales it is called an **eigenvalue** corresponding to that eigenvector.\n",
    "\n",
    "More formally, a vector $v$ is an eigenvector of the matrix $A$, corresponding to the eigenvalue $\\lambda$ if\n",
    "$$ Av = \\lambda v $$\n",
    "\n",
    "You can find more details about the computation [here](https://www.calvin.edu/~scofield/courses/m256/materials/eigenstuff.pdf).\n",
    "\n",
    "Why are these useful? For example, all of quantum physics is based on eigenvalues and eigenvectors. Also, it's very useful in **dimensionality reduction** problems. If you wish, you can explore that (for example, the principal component analysis algorithm)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Problem 7. Principal Component Analysis\n",
    "Sometimes a projection of a higher-dimensional to a lower-dimensional space is useful. It's extremely useful if we want to get some visual understanding of a, say, 15D space, in 3D or even 2D. One algorithm which allows us to project multidimensional data into fewer dimensions **while keeping the most important shapes and structures** is called **principal component analysis** (PCA). You can explore this using the following checklist:\n",
    "* What are eigenvalues and eigenvectors?\n",
    "* What is the eigenbasis? What is the spectrum of a matrix?\n",
    "* How do we compute the eigenvalues and eigenvectors of a matrix?\n",
    "* What is projection?\n",
    "* How does projection conserve some shapes? Think about an object casting a shadow\n",
    "* How is the projection problem related to eigenvalues and eigenvectors?\n",
    "* What is PCA?\n",
    "* What are principal components? How many components are there (as a function of dimensions of the original space)?\n",
    "* What is variance? What is explained variance?\n",
    "* How do principal components relate to explained variance?\n",
    "* How is PCA implemented? Implement and show\n",
    "* Show some applications of PCA, e.g. reducing a 3D image to its first 2 principal components, plotting the 3D and 2D images\n",
    "* Show a practical use of PCA, for example, trying to see features in a 15D space, projected in 3D."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Problem 8. Eigenfaces\n",
    "Another great use of eigenvalues and eigenvectors can be **feature detection**. In one algorithm, called **eigenfaces**, if you receive many images of faces, you can see \"what makes a face\". The principal characteristics of a face can be extracted using something similar to PCA.\n",
    "\n",
    "You can see more info about the topic [at Wikipedia](https://en.wikipedia.org/wiki/Eigenface).\n",
    "\n",
    "Use the checklist from above, but add information about the \"eigenfaces\" algorithm.\n",
    "* How are images represented?\n",
    "* How are the images transformed?\n",
    "* What is an eigenface? Why does it look like a typical (albeit blurry) face?\n",
    "* Implement the algorithm\n",
    "* Train the algorithm on some face images\n",
    "* Show what the eigenfaces you got look like\n",
    "* Use the algorithm for face detection **in an unknown image**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Problem 9. Clustering Analysis. How Different Metrics Affect Clustering Results\n",
    "One important application of linear algebra is to calculate distances between two points. There are many different ways to calculate a distance. The one which is probably most familiar to you is the **Euclidean distance**. In 2D space, given points $A (x_A; y_A)$ and $B(x_B; y_B)$, the distance is \n",
    "$$ d = \\sqrt{(x_B-x_A)^2 + (y_B-y_A)^2} = \\sqrt{(\\Delta x)^2 + (\\Delta y)^2} $$\n",
    "\n",
    "There are many more definitions of distance (see for example \"taxicab distance\").\n",
    "\n",
    "Many algorithms in data processing and machine learning depend on calculating distances, mainly for calculating errors. A class of algorithms which is based on distances is called **cluster analysis**. Explore what cluster analysis is, and how different distance metrics (e.g. Eucledian and its derivate metrics, taxicab, hexagonal, octagonal, etc.) affect the quality of clustering. Of course, the type of metric you're going to use depends mostly on the data. Explore different scenarios and see why one is better than the other in a particular case.\n",
    "\n",
    "* What are clusters of points? Why does real-world data tend to clusterize?\n",
    "* What is clustering analysis? (Optional: What is unsupervised learning?)\n",
    "* Provide examples of clustering analysis in 2D\n",
    "* How are clusters defined?\n",
    "* What is k-means clustering? Why does it converge?\n",
    "* How does k-means depend on the initialization?\n",
    "* How can we reduce the dependency on the initialization?\n",
    "* What is agglomerative clustering (also called hierarchical clustering)?\n",
    "* Implement (or use a ready-made implementation) k-means and agglomerative clustering\n",
    "* The algorithms heavily depend on calculating distances between points. Show the results first using the Euclidean metric\n",
    "* Use another metric (or several other metrics). Compare the results\n",
    "* Use a custom metric. For example, this might be a function defined manually\n",
    "* In which cases is a custom metric applicable?\n",
    "* Apply clustering analysis for a real-world scenario. Some applications include social graphs (relations among people) of all sorts, connected crimes and classification.\n",
    "* Use different distance metrics on the same dataset. How does it affect the data in general?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
